Hi All, my simple randomForest (nodesize=1, ntree=1000) without any words from Corpus scored .92999 on the public leaderboard and .90774 on the private one. I could realise indeed, that any Corpus words selection was likely to make my model overfit on the test data.

my dataset use 4 more variables : WordCountHeadline and isQuestion (no need to explain) bigram_proba [-1,1] and trigram_proba [-1,1]  : -1 is more likely to be unPopular, 1 is more likely to be Popular, 0 is neutral.

I have used a numerical approach from bigrams and trigrams from the Headline Corpus to compute two variables bigram_proba and trigram_proba [-1,1]. Don't get fooled by the name, they are not probabilities at all but I was too lazy to change name. Those variables are built using the mean of popularity for every ngram weighted by their frequencies.

In all my models, the accuracy and AUC was a little bit improved by those 4 variables

$ LogWordCount : num 6.32 5.81 7.14 7.28 5.44 ...
$ Hour : num 22 21 21 20 18 18 18 18 17 16 ...
$ Weekday : Factor w/ 7 levels "0","1","2","3",..: 2 2 2 2 2 2 2 2 2 2 ...
$ NewsDesk : Factor w/ 13 levels "","Business",..: 2 3 2 2 9 9 9 9 8 3 ...
$ SectionName : Factor w/ 16 levels "","Arts","Business Day",..: 4 2 3 3 5 5 5 5 10 2 ...
$ SubsectionName : Factor w/ 9 levels "","Asia Pacific",..: 1 1 3 3 1 1 1 1 1 1 ...
$ WordCountHeadline: int 3 7 8 4 6 5 4 5 7 6 ...
$ isQuestion : logi FALSE FALSE FALSE FALSE FALSE FALSE ...
$ bigram_proba : num 0 0 -0.0216 0 0 ...
$ trigram_proba : num 0 0 0 0 0 ...
$ Popular : Factor w/ 2 levels "No","Yes": 2 1 1 2 2 2 1 2 2 1 ...
