training<-Wage[inTrain, ]
testing<-Wage[-inTrain, ]
install.packages("kernlab")
?prcomp
library(kernlab)
library(caret)
data(spam)
inTrain<-createDataPartition(y=spam$type, p=0.75,list=FALSE)
training<-spam[inTrain, ]
testing<-spam[-inTrain, ]
smallSpam<-spam[,c(34,32)]
prComp<-prcomp(smallSpam)
prComp
spam[,-58]
head(spam[,-58])
spam[,-58]+1
head(spam[,-58]+1)
head(spam)
prcomp(log10(spam[,-58]+1))
prComp<-prcomp(log10(spam[,-58]+1))
prComp
prComp
preProc<-preProcess(log10(spam[,-58]+1), method="pca",pcaComp=2)
trainPC<-predict(preProc, log10(training[,-58]+1))
fit<-train(training$type~., method="glm",data=trainPC)
fit<-train(training$type ~ ., method="glm",data=trainPC)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
data(concrete)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
inTrain
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(mixtures)
summary(mixtures)
head(mixture)
View(mixtures)
plot(mixtures$CompressiveStrength)
?cut2
install.packages("Hmisc")
?cut2
?cut2()
??cut2()
summary(mixtures)
plot(training$CompressiveStrength, col=cut2(Cement, g=10) )
library(Hmisc)
plot(training$CompressiveStrength, col=cut2(Cement, g=10) )
plot(training$CompressiveStrength, col=cut2(training$Cement, g=10) )
plot(training$CompressiveStrength, col=cut2(training$BlastFurnaceSlag, g=10) )
plot(training$CompressiveStrength, col=cut2(training$FlyAsh, g=10) )
plot(training$CompressiveStrength, col=cut2(training$Water, g=10) )
plot(training$CompressiveStrength, col=cut2(training$Superplasticizer, g=10) )
plot(training$CompressiveStrength, col=cut2(training$CoarseAggregate, g=10) )
plot(training$CompressiveStrength, col=cut2(training$FineAggregate, g=10) )
plot(training$CompressiveStrength, col=cut2(training$Age, g=10) )
plot(training$CompressiveStrength, col=cut2(training$FlyAsh, g=10) )
plot(training$CompressiveStrength, col=cut2(training$Age, g=10) )
hist(training$SuperPlasticizer)
training$SuperPlasticizer
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$SuperPlasticizer)
View(training)
names(training)
training$Superplasticizer
hist(training$Superplasticizer)
hist(log(training$Superplasticizer))
View(training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
names(training)
?grep
grep("IL", names(training))
grep("IL", names(training), value=TRUE
)
training[,grep("IL", names(training))]
?preProcess
preProc<-preProcess(training[,grep("IL", names(training))],method="pca")
M<-abs(cor(training[,grep("IL", names(training))]))
diag(M)<-0
which(M>0.8, arr.ind=T)
M
preProc
p<-preProcess(training[,grep("IL", names(training))],method="pca")
p
trainPC<-predict(p, training[,grep("IL", names(training))])
View(trainPC)
fit<-train(training$diagnosis ~ ., method="glm", data=trainPC)
fit<-train(training$diagnosis ~ ., method="lm", data=trainPC)
?train
View(trainPC)
fit<-train(training$diagnosis ~ ., data=trainPC, method="glm")
?preProcess
p<-preProcess(training[,grep("IL", names(training))],method="pca", thresh=0.8)
trainPC<-predict(p, training[,grep("IL", names(training))])
View(trainPC)
names(trainPC)
grep("IL", names(predictors))
grep("IL", names(adData)
)
training = adData[ inTrain, c(grep("IL", names(adData)),1)]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain, c(grep("IL", names(adData)),1)]
View(training)
training = adData[ inTrain, c(1,grep("IL", names(adData)))]
testing = adData[-inTrain,, c(1,grep("IL", names(adData)))]
testing = adData[-inTrain,c(1,grep("IL", names(adData)))]
names(train)
names(training)
fit1<-train(diagnosis~.,data=training, method="glm")
install.packages("e1071")
p<-preProcess(training,method="pca", thresh=0.8)
View(training)
p<-preProcess(training[,-1],method="pca", thresh=0.8)
trainPC<-predict(p, training[,-1])
fit2<-train(training$diagnosis~.,data=training, method="glm")
fit1<-train(diagnosis~.,data=training, method="glm")
confusionMatrix(testing$diagnosis, predict(fit1, testing))
p<-preProcess(training[,-1],method="pca", thresh=0.8)
trainPC<-predict(p, training[,-1])
fit2<-train(training$diagnosis~.,data=training, method="glm")
testPC<-predict(p, testing[,-1])
confusionMatrix(testing$diagnosis, predict(fit2, testPC))
View(testPC)
View(testing)
summry(fit2)
summary(fit2)
fit2<-train(training$diagnosis~.,data=training, method="glm")
summary(fit2)
View(trainPC)
confusionMatrix(testing$diagnosis, predict(fit2, testing[,-1]))
predict(fit2, testing[,-1])
fit1<-train(diagnosis~.,data=training, method="glm")
fit1<-train(diagnosis~.,data=training, method="glm")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain, c(1,grep("IL", names(adData)))]
testing = adData[-inTrain,c(1,grep("IL", names(adData)))]
fit1<-train(diagnosis~.,data=training, method="glm")
confusionMatrix(testing$diagnosis, predict(fit1, testing[,-1]))
p<-preProcess(training[,-1],method="pca", thresh=0.8)
trainPC<-predict(p, training[,-1])
fit2<-train(training$diagnosis~.,data=training, method="glm")
confusionMatrix(testing$diagnosis, predict(fit2, testing[,-1]))
summary(fit1)
sumary(fit2)
summary(fit2)
trainPC<-predict(p, training[,-1])
p<-preProcess(training[,-1],method="pca", thresh=0.8)
trainPC<-predict(p, training[,-1])
fit2<-train(training$diagnosis~.,data=training, method="glm")
summary(fit2)
confusionMatrix(testing$diagnosis, predict(fit1, testing[,-1]))
confusionMatrix(testing$diagnosis, predict(fit2, testing[,-1]))
fit2<-train(training$diagnosis~.,data=trainPC, method="glm")
summary(fit2)
p<-preProcess(training[,-1],method="pca", thresh=0.8)
trainPC<-predict(p, training[,-1])
fit2<-train(training$diagnosis~.,data=trainPC, method="glm")
testPC<-predict(p, testing[,-1])
confusionMatrix(testing$diagnosis, predict(fit2, testPC))
View(testPC)
View(testPC)
fit3<-lm(training$diagnosis ~ ., data=trainPC)
summary(fit3)
summary(fit1)
fit3<-lm(diagnosis ~ ., data=data.frame(diagnosis,trainPC))
fit3<-lm(diagnosis ~ ., data=data.frame(training$diagnosis,trainPC))
training$diagnosis
data.frame(training$diagnosis,trainPC
)
head(data.frame(training$diagnosis,trainPC))
fit3<-lm(diagnosis ~ ., data=data.frame(diagnosis=training$diagnosis,trainPC))
fit3<-lm(training$diagnosis~.,data=trainPC)
fit3<-glm(training$diagnosis~.,data=trainPC)
summary(trainPC)
summary(diagnosis)
View(training)
set.seed(12345)
fit1<-train(diagnosis~.,data=training, method="glm")
confusionMatrix(testing$diagnosis, predict(fit1, testing[,-1]))
confusionMatrix(testing$diagnosis, predict(fit1, testing))
set.seed(12345)
p<-preProcess(training[,-1],method="pca", thresh=0.8)
trainPC<-predict(p, training[,-1])
fit2<-train(training$diagnosis~.,data=trainPC, method="glm")
testPC<-predict(p, testing[,-1])
confusionMatrix(testing$diagnosis, predict(fit2, testPC))
p<-preProcess(training[,-1],method="pca")
trainPC<-predict(p, training[,-1])
fit2<-train(training$diagnosis~.,data=trainPC, method="glm")
testPC<-predict(p, testing[,-1])
confusionMatrix(testing$diagnosis, predict(fit2, testPC))
p<-preProcess(training[,-1],method="pca",thresh=0.8)
trainPC<-predict(p, training[,-1])
fit2<-train(training$diagnosis~.,data=trainPC, method="glm")
testPC<-predict(p, testing[,-1])
confusionMatrix(testing$diagnosis, predict(fit2, testPC))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain, c(1,grep("IL", names(adData)))]
testing = adData[-inTrain,c(1,grep("IL", names(adData)))]
fit1<-train(diagnosis~.,data=training, method="glm")
confusionMatrix(testing$diagnosis, predict(fit1, testing))
confusionMatrix(testing$diagnosis, predict(fit1, newdata=testing))
?train
fit2<-train(training$diagnosis~.,data=trainPC, method="glm", preProcess="pca", trControl=trainControl(thresh = 0.95))
?list
fit2<-train(training$diagnosis~.,data=trainPC, method="glm", preProcess="pca", trControl=trainControl(preProcOptions=list(thresh = 0.95))
)
confusionMatrix(testing$diagnosis, predict(fit2, testing))
fit2<-train(training$diagnosis~.,data=training, method="glm", preProcess="pca",
trControl=trainControl(preProcOptions=list(thresh = 0.95)))
confusionMatrix(testing$diagnosis, predict(fit2, testing))
# PCA
fit2<-train(training$diagnosis~.,data=training, method="glm", preProcess="pca",
trControl=trainControl(preProcOptions=list(thresh = 0.8)))
confusionMatrix(testing$diagnosis, predict(fit2, testing))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
hist(log(training$Superplasticizer))
hist(training$Superplasticizer)
hist(log(training$Superplasticizer))
hist(log(training$Superplasticizer+1))
library(caret)
library(AppliedPredictiveModeling)
set.seed(13433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain, c(1,grep("IL", names(adData)))]
testing = adData[-inTrain,c(1,grep("IL", names(adData)))]
fit1<-train(diagnosis~.,data=training, method="glm")
confusionMatrix(testing$diagnosis, predict(fit1, newdata=testing))
fit2<-train(training$diagnosis~.,data=training, method="glm", preProcess="pca",
trControl=trainControl(preProcOptions=list(thresh = 0.8)))
confusionMatrix(testing$diagnosis, predict(fit2, testing))
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
install.packages("randomForest")
library(randomForest)
head(iris)
table(iris$Species)
# Define the design matrix and the classifciation target
X <iris[, 1:4]
X <-iris[, 1:4]
Y <-iris$Species
rf <randomForest(  x=X, y=Y, ntree=200, do.trace=T)
rf <-randomForest(x=X, y=Y, ntree=200, do.trace=T)
rf
plot(rf)
importance(rf)
barplot(t(importance(rf)), col=4)
sd(c(5,8,12))
which.min(c(4,1,6))
Sys.setlocale("LC_ALL", "C")
setwd("D:/doc/study/15.071x The Analytics Edge/unit1")
WHO<-read.csv("WHO.csv")
str(WHO)
summary(WHO$Over60)
which.min(WHO$Over60)
which.min(WHO$Over60)
WHO[86]
WHO[183,]
which.max(WHO$FertilityRate)
WHO[124,]
WHO[124,"country"]
WHO[183,"Country"]
WHO[124,"Country"]
which.max(WHO$LiteracyRate)
WHO[44,"Country"]
str(WHO)
tapply(WHO$ChildMortality, WHO$Region, mean)
setwd("D:/doc/study/15.071x The Analytics Edge/unit1")
setwd("D:/doc/study/15.071x The Analytics Edge/unit1")
mvt<-read.csv("mvtWeek1.csv")
summary(mvt)
str(mvt)
max(mvt$ID)
min(mvt$Beat)
summary(mvt$Arrest)
table(mvt$LocationDescription)
nrow(subset(mvt, LocationDescription=="ALLEY"))
mvt$DATE[1]
str(mvt)
mvt$Date[1]
DateConvert = as.Date(strptime(mvt$Date, "%m/%d/%y %H:%M"))
summary(DateConvert)
mvt$Month = months(DateConvert)
mvt$Weekday = weekdays(DateConvert)
mvt$Date = DateConvert
table(mvt$Month)
table(mvt$year)
table(mvt$Year)
max(mvt$DateConvert)
mvt$DateConvert
setwd("D:/doc/study/15.071x The Analytics Edge/unit1")
max(mvt$Date)
table(mvt$year, mvt$month)
table(mvt$Year, mvt$Month)
View(mvt)
table(mvt$Month)
table(mvt$Weekday)
summary(mvt$Arrest)
table(subset(mvt, Arrest==TRUE, Month))
hist(mvt$Date, breaks=100)
hist(mvt$Date, breaks=50)
hist(mvt$Date, breaks=100)
boxplot(mvt$Date, mvt$Arrest)
boxplot(mvt$Arrest,mvt$Date)
boxplot(mvt$Date, mvt$Arrest)
?boxplot
boxplot(Date~Arrest, data=mvt)
table(subset(mvt, Year==2001, Arrest))
prop.table(subset(mvt, Year==2001, Arrest))
2151/(18517+2151)
table(subset(mvt, Year==2007, Arrest))
1212/(13068+1212)
table(subset(mvt, Year==2012, Arrest))
550/(13542+550)
sort(table(mvt$LocationDescription))
top5<-subset(mvt,LocationDescription=="STREET"|LocationDescription=="PARKING LOT/GARAGE(NON.RESID.)"|LocationDescription=="ALLEY"|LocationDescription=="GAS STATION"|LocationDescription=="DRIVEWAY - RESIDENTIAL") )
top5<-subset(mvt,LocationDescription=="STREET"|LocationDescription=="PARKING LOT/GARAGE(NON.RESID.)"|LocationDescription=="ALLEY"|LocationDescription=="GAS STATION"|LocationDescription=="DRIVEWAY - RESIDENTIAL" )
summary(top5)
str(top5)
Top5$LocationDescription = factor(Top5$LocationDescription)
Top5<-subset(mvt,LocationDescription=="STREET"|LocationDescription=="PARKING LOT/GARAGE(NON.RESID.)"|LocationDescription=="ALLEY"|LocationDescription=="GAS STATION"|LocationDescription=="DRIVEWAY - RESIDENTIAL" )
Top5$LocationDescription = factor(Top5$LocationDescription)
str(Top5)
table(Top5$LocationDescription, Top5$Arrest)
prop.table(Top5$LocationDescription, Top5$Arrest,1)
?prop.table
prop.table(Top5$LocationDescription, Top5$Arrest,margin=1)
prop.table(table(Top5$LocationDescription, Top5$Arrest),margin=1)
table(subset(Top5, LocationDescription=="GAS STATION", Weekday))
table(subset(Top5, LocationDescription=="DRIVEWAY - RESIDENTIAL", Weekday))
setwd("D:/doc/study/15.071x The Analytics Edge/unit1")
IBM<-read.csv("IBMStock.csv")
GE<-read.csv("GEStock.csv")
ProcterGamble<-read.csv("ProcterGambleStock.csv")
CocaCola<-read.csv("CocaColaStock.csv")
Boeing<-read.csv("BoeingStock.csv")
IBM$Date = as.Date(IBM$Date, "%m/%d/%y")
GE$Date = as.Date(GE$Date, "%m/%d/%y")
CocaCola$Date = as.Date(CocaCola$Date, "%m/%d/%y")
ProcterGamble$Date = as.Date(ProcterGamble$Date, "%m/%d/%y")
Boeing$Date = as.Date(Boeing$Date, "%m/%d/%y")
min(IBM$Date)
min(GE$Date)
max(IBM$Date)
mean(IBM$StockPrice)
min(GE$StockPrice)
max(CocaCola$StockPrice)
median(Boeing$StockPrice)
sd(ProcterGamble$StockPrice)
plot(CocaCola$Date, CocaCola$StockPrice)
plot(CocaCola$Date, CocaCola$StockPrice, type='l')
lines(ProcterGamble$Date, ProcterGamble$StockPrice)
lines(ProcterGamble$Date, ProcterGamble$StockPrice, color="RED")
lines(ProcterGamble$Date, ProcterGamble$StockPrice, color="red")
lines(ProcterGamble$Date, ProcterGamble$StockPrice, col="red")
plot(CocaCola$Date, CocaCola$StockPrice, type='l', col="red")
lines(ProcterGamble$Date, ProcterGamble$StockPrice, col="blue")
abline(v=as.Date(c("2000-03-01")), lwd=2)
abline(v=as.Date(c("1983-01-01")), lwd=2)
abline(v=as.Date(c("1984-01-01")), lwd=2)
plot(CocaCola$Date[301:432], CocaCola$StockPrice[301:432], type="l", col="red", ylim=c(0,210))
lines(ProcterGamble$Date[301:432], ProcterGamble$StockPrice[301:432], col="blue")
abline(v=as.Date(c("2000-03-01")), lwd=2)
lines(IBM$Date[301:432], IBM$StockPrice[301:432], col="green")
lines(GE$Date[301:432], GE$StockPrice[301:432], col="black")
lines(Boeing$Date[301:432], Boeing$StockPrice[301:432], col="orange")
abline(v=as.Date(c("1997-09-01")), lwd=2)
abline(v=as.Date(c("1997-12-01")), lwd=2)
abline(v=as.Date(c("2004-01-01")), lwd=2)
abline(v=as.Date(c("2006-01-01")), lwd=2)
months(IBM$Date)
tapply(IBM$StockPrice, months(IBM$Date), mean)
mean(IBM$StockPrice)
tapply(CocaCola$StockPrice, months(CocaCola$Date), mean)
tapply(ProcterGamble$StockPrice, months(ProcterGamble$Date), mean)
tapply(CocaCola$StockPrice, months(CocaCola$Date), mean)
tapply(GE$StockPrice, months(GE$Date), mean)
setwd("D:/doc/study/15.071x The Analytics Edge/unit1")
IBM<-read.csv("CPSData.csv")
CPS<-read.csv("CPSData.csv")
summary(CPS)
View(CPS)
str(CPS)
sort(table(CPS$Region))
sort(table(CPS$State))
table(CPS$Citizenship)
116639/131302
(116639+7073)/131302
summary(CPS$Hispanic)
table(CPS$Hispanic)
table(CPS$Hispanic, CPS$race)
table(CPS$Hispanic, CPS$Race)
summary(CPS)
table(CPS$Region, is.na(CPS$Married))
table(CPS$Sex, is.na(CPS$Married))
table(CPS$Age, is.na(CPS$Married))
table(CPS$Citizenship, is.na(CPS$Married))
is.na(MetroAreaCode)
is.na(CPS$MetroAreaCode)
table(CPS[is.na(CPS$MetroAreaCode),"State"])
table(CPS$State, is.na(CPS$MetroAreaCode))
prop.table(table(CPS$State, is.na(CPS$MetroAreaCode)))
p
?prop.table
prop.table(table(CPS$State, is.na(CPS$MetroAreaCode)), 1)
prop.table(table(CPS$Region, is.na(CPS$MetroAreaCode)), 1)
tapply(is.na(CPS$MetroAreaCode), CPS$region, mean)
tapply(is.na(CPS$MetroAreaCode), CPS$Region, mean)
tapply(is.na(CPS$MetroAreaCode), CPS$State, mean)
sort(tapply(is.na(CPS$MetroAreaCode), CPS$State, mean))
MetroAreaMap<-read.csv("MetroAreaCodes.csv")
CountryOfBirthCode<-read.csv("CountryCodes.csv")
MetroAreaMap<-read.csv("MetroAreaCodes.csv")
CountryMap<-read.csv("CountryCodes.csv")
CPS<-read.csv("CPSData.csv")
CPS = merge(CPS, MetroAreaMap, by.x="MetroAreaCode", by.y="Code", all.x=TRUE)
str(CPS)
summary(CPS)
sort(table(CPS$MetroArea))
tapply(CPS$Hispanic, CPS$MetroArea, mean)
sort(tapply(CPS$Hispanic, CPS$MetroArea, mean))
tapply(CPS$Race == "Asian", CPS$MetroArea, mean)
sort(tapply(CPS$Race == "Asian", CPS$MetroArea, mean))
tapply(CPS$Hispanic, CPS$MetroArea, mean)>0.2
sum(sort(tapply(CPS$Race == "Asian", CPS$MetroArea, mean)))
sum(tapply(CPS$Race == "Asian", CPS$MetroArea, mean)>0.2)
sum(tapply(CPS$Race == "Asian", CPS$MetroArea, mean)>=0.2)
sum(tapply(CPS$Hispanic, CPS$MetroArea, mean)>0.2)
dim(tapply(CPS$Hispanic, CPS$MetroArea, mean)>0.2)
table(tapply(CPS$Hispanic, CPS$MetroArea, mean)>0.2)
table(tapply(CPS$Race == "Asian", CPS$MetroArea, mean)>0.2)
sort(tapply(CPS$Education == "No high school diploma", CPS$MetroArea, mean, rm.na=TRUE))
sort(tapply(CPS$Education == "No high school diploma", CPS$MetroArea, mean, na.rm=TRUE))
str(CountryMap)
str(CPS)
CPS = merge(CPS, CountryMap, by.x="CountryOfBirthCode", by.y="Code", all.x=TRUE)
str(CPS)
summary(CPS)
table(CPS$Country)
sort(table(CPS$Country))
sort(tapply(CPS$MetroArea=="New York-Northern New Jersey-Long Island, NY-NJ-PA", CPS$Country, mean, na.rm=TRUE))
sort(table(CPS$Country))
sort(tapply(CPS$MetroArea=="New York-Northern New Jersey-Long Island, NY-NJ-PA", CPS$Country=="United States", mean, na.rm=TRUE))
tapply(CPS$MetroArea=="New York-Northern New Jersey-Long Island, NY-NJ-PA", CPS$Country=="United States", mean, na.rm=TRUE)
table(CPS$MetroArea=="New York-Northern New Jersey-Long Island, NY-NJ-PA", CPS$Country=="United States", mean, na.rm=TRUE)
table(CPS$MetroArea=="New York-Northern New Jersey-Long Island, NY-NJ-PA", CPS$Country=="United States")
table(subset(CPS, MetroArea=="New York-Northern New Jersey-Long Island, NY-NJ-PA"), CPS$Country=="United States")
tapply(subset(CPS, MetroArea=="New York-Northern New Jersey-Long Island, NY-NJ-PA"), CPS$Country=="United States", mean, na.rm=TRUE)
subset(CPS, MetroArea=="New York-Northern New Jersey-Long Island, NY-NJ-PA")
tapply(CPS$MetroArea=="New York-Northern New Jersey-Long Island, NY-NJ-PA", CPS$Country=="United States", mean, na.rm=TRUE)
table(CPS$MetroArea=="New York-Northern New Jersey-Long Island, NY-NJ-PA", CPS$Country=="United States")
1668/(1668+3736)
table(CPS$Country=="India", CPS$MetroArea )
sort(table(CPS$Country=="India", CPS$MetroArea ))
table(CPS$Country=="India", CPS$MetroArea)
table(CPS$MetroArea, CPS$Country=="India")
sort(table(CPS$MetroArea, CPS$Country=="India"))
table(CPS$MetroArea, CPS$Country=="India")
table(CPS$MetroArea, CPS$Country=="Brazil")
table(CPS$MetroArea, CPS$Country=="Brazil")
table(CPS$MetroArea, CPS$Country=="India")
table(CPS$MetroArea, CPS$Country=="Brazil")
table(CPS$MetroArea, CPS$Country=="Somalia")
